# Lex Pipeline Analysis Tools

This directory contains analysis scripts for monitoring and analyzing the Lex pipeline's performance, errors, and data quality.

## Quick Start - Run All Analyses

```bash
# Run all analyses from the lex root directory
python analysis/run_all_analyses.py

# Or from within the analysis directory
cd analysis
python run_all_analyses.py
```

## Core Scripts

### Base Infrastructure
- **`base_analyzer.py`** - Base class providing Elasticsearch connection and common query methods
- **`common_utils.py`** - Shared utility functions for parsing log messages, extracting metadata, and formatting

### Pipeline Monitoring
- **`pipeline_monitoring.py`** - Comprehensive pipeline status, progress tracking, and logging quality analysis
  - Monitors pipeline completions and active runs
  - Checks structured logging implementation
  - Tracks throughput and batch processing metrics
  - Usage: `python pipeline_monitoring.py [hours]` (default: 24 hours)

### Error Analysis
- **`error_type_analyzer.py`** - Comprehensive error analysis including failed XML URL extraction
  - Categorizes all error types (PDF fallbacks, HTTP errors, parsing errors, validation errors)
  - Extracts failed XML URLs and validation error documents
  - Provides error distribution by type and document type
  - Includes CommentaryCitation and other validation error analysis
  - Outputs multiple files: error report, failed URLs, validation errors

### Data Quality Analysis
- **`xml_completeness_comprehensive.py`** - Comprehensive XML completeness analysis
  - Analyzes all document types or specific types
  - Shows XML availability by year with accurate statistics
  - Generates heatmaps of digitization rates
  - Usage: `python xml_completeness_comprehensive.py [type]`
  - Example: `python xml_completeness_comprehensive.py uksi`

- **`explanatory_note_analyzer.py`** - Analyzes explanatory notes coverage
  - Shows availability by year and legislation type
  - Identifies gaps in coverage

### Performance Analysis
- **`processing_performance_analyzer.py`** - Analyzes pipeline throughput and performance metrics
  - Tracks processing speed over time
  - Monitors batch sizes and upload patterns
  - Identifies performance bottlenecks

### Orchestration
- **`run_all_analyses.py`** - Runs all analysis scripts in sequence
  - Automatically runs all analyses with appropriate parameters
  - Generates comprehensive report suite for all document types

## Output Files

All scripts generate JSON reports in the `analysis/` directory:

- `error_type_report.json` - Error categorization and statistics (includes failed URLs and validation errors)
- `xml_completeness_report.json` - XML availability analysis for all document types
- `performance_report.json` - Processing performance metrics
- `explanatory_note_report.json` - Explanatory notes coverage
- `failed_xml_urls.json` - URLs of documents with XML parsing errors (generated by error_type_analyzer)
- `validation_error_documents.json` - Documents with validation errors (generated by error_type_analyzer)

## Running Individual Scripts

```bash
# Monitor pipeline status (default: last 24 hours)
python pipeline_monitoring.py
python pipeline_monitoring.py 48  # Last 48 hours

# Analyze error types (includes failed URL extraction)
python error_type_analyzer.py

# Analyze XML completeness - all types
python xml_completeness_comprehensive.py

# Analyze XML completeness - specific type
python xml_completeness_comprehensive.py uksi
python xml_completeness_comprehensive.py ukpga

# Analyze processing performance
python processing_performance_analyzer.py

# Analyze explanatory notes coverage
python explanatory_note_analyzer.py
```

## Requirements

- Access to Elasticsearch instance with pipeline logs
- Python packages: elasticsearch, python-dotenv
- Environment variables configured for Elasticsearch connection